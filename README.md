# Toxic-Comment-Classification
The Toxic Comment Classification Challenge is a competition from Kaggle, which is headed by the Conversation AI team, a research intitative founded by Jigsaw ang Google. One of the projects made by the team is to study the negative online behaviors, especially on toxic comments. This competition is purposefully done to build a multi class model that's able to correctly classify 6 differents types of toxicity, namely: toxic, severe toxic, obscene, threat, insult, and identity hate.

# Prerequisites
  ### Modules
  - Scikit learn
  - Pandas
  - Numpy
  - Matplotlib
  - Regular Expressions
  
  ### Data
The data can be downloaded in [here](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)
